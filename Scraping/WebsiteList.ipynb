{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fefff0f1",
   "metadata": {},
   "source": [
    "### -------------------- SLOW CODE -----------------------\n",
    "--------- IMPORT EVERYTHING , TRY MANY ATTEMPET TILL SUCCES ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4699e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing page 1...\n",
      "Request failed: Unexpected response: 403\n",
      "Attempt 1 failed for page 1: Unexpected response: 403\n",
      "Request failed: Unexpected response: 403\n",
      "Attempt 2 failed for page 1: Unexpected response: 403\n",
      "Request failed: Unexpected response: 403\n",
      "Attempt 3 failed for page 1: Unexpected response: 403\n",
      "Successfully saved 10 items from page 1\n",
      "\n",
      "Processing page 2...\n",
      "Successfully saved 10 items from page 2\n",
      "\n",
      "Processing page 3...\n",
      "Request failed: Unexpected response: 403\n",
      "Attempt 1 failed for page 3: Unexpected response: 403\n",
      "Successfully saved 10 items from page 3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Enhanced configuration\n",
    "USER_AGENTS = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/118.0',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "]\n",
    "\n",
    "HEADERS = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "    'DNT': '1',\n",
    "    'Referer': 'https://jadaero.com/',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "\n",
    "# Configure session with aggressive retry\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=10,\n",
    "    backoff_factor=2,\n",
    "    status_forcelist=[429, 500, 502, 503, 504, 520, 521, 522, 523, 524],\n",
    "    allowed_methods=[\"GET\", \"HEAD\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=50, pool_maxsize=50)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)\n",
    "\n",
    "def make_request(url):\n",
    "    \"\"\"Make request with randomized headers and delays\"\"\"\n",
    "    headers = HEADERS.copy()\n",
    "    headers['User-Agent'] = random.choice(USER_AGENTS)\n",
    "    \n",
    "    try:\n",
    "        time.sleep(random.uniform(10, 30))  # 10-30 second delay\n",
    "        \n",
    "        response = session.get(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            timeout=(15, 45),  # 15s connect, 45s read timeout\n",
    "            allow_redirects=True\n",
    "        )\n",
    "        \n",
    "        # Additional verification\n",
    "        if response.status_code == 200 and \"wcpt-table\" in response.text:\n",
    "            return response\n",
    "        else:\n",
    "            raise requests.exceptions.RequestException(f\"Unexpected response: {response.status_code}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {str(e)[:200]}\")\n",
    "        raise\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    url = f'https://jadaero.com/aircraft-parts-inventory/?24951_paged={page_num}'\n",
    "    \n",
    "    for attempt in range(5):  # Try each page up to 5 times\n",
    "        try:\n",
    "            response = make_request(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            table = soup.find('table', {'class': 'wcpt-table'})\n",
    "            \n",
    "            if not table:\n",
    "                raise ValueError(\"Table not found in page\")\n",
    "                \n",
    "            rows = []\n",
    "            for row in table.find_all('tr')[1:]:\n",
    "                try:\n",
    "                    cells = row.find_all('td')\n",
    "                    if len(cells) >= 5:\n",
    "                        img_tag = cells[0].find('img')\n",
    "                        name_tag = cells[1].find('a')\n",
    "                        \n",
    "                        rows.append([\n",
    "                            description.split('Part Number:')[1].split('\\n')[0].strip() if 'Part Number:' in (description := cells[2].get_text(separator='\\n').strip()) else '',\n",
    "                            name_tag.text.strip() if name_tag else '',\n",
    "                            description,\n",
    "                            cells[3].find('input', {'name': 'quantity'})['value'] if cells[3].find('input', {'name': 'quantity'}) else '1',\n",
    "                            img_tag['src'] if img_tag else '',\n",
    "                            name_tag['href'] if name_tag else ''\n",
    "                        ])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing row: {str(e)[:200]}\")\n",
    "                    continue\n",
    "            \n",
    "            return rows\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for page {page_num}: {str(e)[:200]}\")\n",
    "            time.sleep(60 * (attempt + 1))  # Wait 1-5 minutes between attempts\n",
    "            continue\n",
    "    \n",
    "    return None  # All attempts failed\n",
    "\n",
    "# Main scraping process\n",
    "with open('jadaero_parts.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Part Number', 'Name', 'Description', 'Quantity', 'Image URL', 'Product URL'])\n",
    "    \n",
    "    for page in range(1, 51):\n",
    "        print(f\"\\nProcessing page {page}...\")\n",
    "        \n",
    "        data = scrape_page(page)\n",
    "        if data:\n",
    "            writer.writerows(data)\n",
    "            print(f\"Successfully saved {len(data)} items from page {page}\")\n",
    "        else:\n",
    "            print(f\"Failed to process page {page} after multiple attempts\")\n",
    "            \n",
    "        # Random long delay between pages\n",
    "        time.sleep(random.uniform(30, 120))\n",
    "\n",
    "print(\"\\nScraping completed! Results saved to jadaero_parts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044e4cf",
   "metadata": {},
   "source": [
    "### -------------------- FAST CODE ------------------- \n",
    "--------- SKIP NON IMPORTANT OR CAUSE OF CRASH PAGE ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851bfcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 10 items\n",
      "Page 2: 10 items\n",
      "Page 3: 10 items\n",
      "Page 4: 10 items\n",
      "Page 5: 10 items\n",
      "Page 6: 10 items\n",
      "Page 7: 10 items\n",
      "Page 8: 10 items\n",
      "Page 9: 10 items\n",
      "Page 10: 10 items\n",
      "Page 11: 10 items\n",
      "Page 12: 10 items\n",
      "Page 13: 10 items\n",
      "Page 14: 10 items\n",
      "Page 15: 10 items\n",
      "Page 16: 10 items\n",
      "Page 17: 10 items\n",
      "Page 18: 10 items\n",
      "Page 19: 10 items\n",
      "Page 20: 10 items\n",
      "Page 21: 10 items\n",
      "Page 22: 10 items\n",
      "Page 23: 10 items\n",
      "Page 24: 10 items\n",
      "Page 25: 10 items\n",
      "Page 26: 10 items\n",
      "Page 27: 10 items\n",
      "Page 28: 10 items\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m                 retry_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;66;03m# Small random delay even on failures\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInitial scrape complete! Now retrying failed pages...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Retry failed pages (only if needed)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import os  # Added this missing import\n",
    "\n",
    "# Lightweight configuration\n",
    "USER_AGENTS = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'\n",
    "]\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    headers = {\n",
    "        'User-Agent': random.choice(USER_AGENTS),\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "    \n",
    "    url = f'https://jadaero.com/aircraft-parts-inventory/?24951_paged={page_num}'\n",
    "    \n",
    "    try:\n",
    "        # Random delay between 5-8 seconds\n",
    "        time.sleep(random.uniform(5, 8))\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'wcpt-table'})\n",
    "        if not table:\n",
    "            return None\n",
    "            \n",
    "        rows = []\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            try:\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) >= 5:\n",
    "                    rows.append([\n",
    "                        cells[1].find('a').text.strip() if cells[1].find('a') else '',\n",
    "                        cells[2].get_text(separator=' ').strip(),\n",
    "                        cells[3].find('input', {'name': 'quantity'})['value'] if cells[3].find('input') else '1'\n",
    "                    ])\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        return rows\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Main scraping process\n",
    "with open('jadaero_parts_fast.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Part Name', 'Description', 'Quantity'])\n",
    "    \n",
    "    for page in range(1, 51):\n",
    "        print(f\"Page {page}\", end='\\r')\n",
    "        \n",
    "        data = scrape_page(page)\n",
    "        if data:\n",
    "            writer.writerows(data)  # Fixed typo here (was writer.writerows)\n",
    "            print(f\"Page {page}: {len(data)} items\")\n",
    "        else:\n",
    "            print(f\"Failed page {page} - will retry later\")\n",
    "            # Add failed pages to retry queue\n",
    "            with open('retry_pages.txt', 'a') as retry_file:\n",
    "                retry_file.write(f\"{page}\\n\")\n",
    "        \n",
    "        # Small random delay even on failures\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "\n",
    "print(\"\\nInitial scrape complete! Now retrying failed pages...\")\n",
    "\n",
    "# Retry failed pages (only if needed)\n",
    "if os.path.exists('retry_pages.txt'):\n",
    "    with open('retry_pages.txt', 'r') as f:\n",
    "        pages_to_retry = [int(line.strip()) for line in f]\n",
    "    \n",
    "    for page in pages_to_retry:\n",
    "        print(f\"Retrying page {page}\", end='\\r')\n",
    "        data = scrape_page(page)\n",
    "        if data:\n",
    "            with open('jadaero_parts_fast.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(data)\n",
    "            print(f\"Successfully retried page {page}\")\n",
    "        \n",
    "        time.sleep(8)  # Longer delay for retries\n",
    "\n",
    "    # Clean up the retry file\n",
    "    os.remove('retry_pages.txt')\n",
    "\n",
    "print(\"\\nAll done! Results saved to jadaero_parts_fast.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
